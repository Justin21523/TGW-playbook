# stages/stage3-default-notebook/prompt_engineering_tool.py
"""
TGW Prompt Engineering Tool
æ™ºèƒ½æç¤ºè©å·¥ç¨‹å’Œç¯„æœ¬ç®¡ç†å·¥å…·

åŠŸèƒ½ï¼š
- æç¤ºè©ç¯„æœ¬ç®¡ç†
- Token æ•ˆç‡åˆ†æ
- A/B æ¸¬è©¦è‡ªå‹•åŒ–
- å“è³ªè©•ä¼°æŒ‡æ¨™
"""

import json
import os
import re
import time
import requests
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from pathlib import Path


@dataclass
class PromptTemplate:
    """æç¤ºè©ç¯„æœ¬é¡åˆ¥"""

    name: str
    category: str
    template: str
    variables: List[str]
    description: str
    tags: List[str]
    optimal_params: Dict[str, float]
    created_at: str


class TGWPromptEngineer:
    """TGW æç¤ºè©å·¥ç¨‹å¸«"""

    def __init__(
        self,
        api_base: str = "http://localhost:5000",
        templates_dir: str = "./configs/prompts",
        results_dir: str = "./results",
    ):
        self.api_base = api_base
        self.templates_dir = Path(templates_dir)
        self.results_dir = Path(results_dir)

        # å»ºç«‹ç›®éŒ„
        self.templates_dir.mkdir(parents=True, exist_ok=True)
        self.results_dir.mkdir(parents=True, exist_ok=True)

        # è¼‰å…¥ç¯„æœ¬
        self.templates = self._load_templates()

    def _load_templates(self) -> Dict[str, PromptTemplate]:
        """è¼‰å…¥æ‰€æœ‰æç¤ºè©ç¯„æœ¬"""
        templates = {}

        for template_file in self.templates_dir.glob("*.json"):
            try:
                with open(template_file, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    template = PromptTemplate(**data)
                    templates[template.name] = template
            except Exception as e:
                print(f"âš ï¸ ç„¡æ³•è¼‰å…¥ç¯„æœ¬ {template_file}: {e}")

        return templates

    def create_template(
        self,
        name: str,
        category: str,
        template: str,
        description: str,
        tags: List[str] = None,
        optimal_params: Dict[str, float] = None,
    ) -> PromptTemplate:
        """å»ºç«‹æ–°çš„æç¤ºè©ç¯„æœ¬"""

        # è‡ªå‹•è­˜åˆ¥è®Šæ•¸
        variables = re.findall(r"\{([^}]+)\}", template)

        # é è¨­åƒæ•¸
        if optimal_params is None:
            optimal_params = {
                "temperature": 0.7,
                "top_p": 0.9,
                "top_k": 40,
                "repetition_penalty": 1.1,
            }

        if tags is None:
            tags = []

        # å»ºç«‹ç¯„æœ¬ç‰©ä»¶
        prompt_template = PromptTemplate(
            name=name,
            category=category,
            template=template,
            variables=variables,
            description=description,
            tags=tags,
            optimal_params=optimal_params,
            created_at=time.strftime("%Y-%m-%d %H:%M:%S"),
        )

        # å„²å­˜ç¯„æœ¬
        self.save_template(prompt_template)
        self.templates[name] = prompt_template

        return prompt_template

    def save_template(self, template: PromptTemplate):
        """å„²å­˜ç¯„æœ¬åˆ°æª”æ¡ˆ"""
        filename = f"{template.category}_{template.name}.json"
        filepath = self.templates_dir / filename

        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(template.__dict__, f, ensure_ascii=False, indent=2)

        print(f"âœ… ç¯„æœ¬å·²å„²å­˜: {filepath}")

    def fill_template(self, template_name: str, variables: Dict[str, str]) -> str:
        """å¡«å…¥è®Šæ•¸ç”Ÿæˆæœ€çµ‚æç¤ºè©"""
        if template_name not in self.templates:
            raise ValueError(f"ç¯„æœ¬ '{template_name}' ä¸å­˜åœ¨")

        template = self.templates[template_name]
        prompt = template.template

        # æ›¿æ›è®Šæ•¸
        for var, value in variables.items():
            prompt = prompt.replace(f"{{{var}}}", value)

        return prompt

    def analyze_tokens(self, text: str) -> Dict:
        """åˆ†ææ–‡æœ¬çš„ token è³‡è¨Š"""
        try:
            response = requests.post(
                f"{self.api_base}/v1/internal/tokenize",
                json={"text": text},
                headers={"Content-Type": "application/json"},
            )

            if response.status_code == 200:
                data = response.json()
                return {
                    "token_count": len(data.get("tokens", [])),
                    "tokens": data.get("tokens", []),
                    "token_ids": data.get("token_ids", []),
                    "efficiency_score": len(text)
                    / len(data.get("tokens", [1])),  # å­—ç¬¦/token æ¯”ç‡
                }
            else:
                print(f"âš ï¸ Token åˆ†æå¤±æ•—: {response.status_code}")
                return {}

        except Exception as e:
            print(f"âŒ Token åˆ†æéŒ¯èª¤: {e}")
            return {}

    def generate_text(
        self, prompt: str, params: Dict[str, any] = None, stream: bool = False
    ) -> Dict:
        """ç”Ÿæˆæ–‡æœ¬"""

        default_params = {
            "temperature": 0.7,
            "top_p": 0.9,
            "top_k": 40,
            "max_new_tokens": 512,
            "repetition_penalty": 1.1,
            "stream": stream,
        }

        if params:
            default_params.update(params)

        try:
            response = requests.post(
                f"{self.api_base}/v1/completions",
                json={"prompt": prompt, **default_params},
                headers={"Content-Type": "application/json"},
            )

            if response.status_code == 200:
                return response.json()
            else:
                print(f"âš ï¸ ç”Ÿæˆå¤±æ•—: {response.status_code}")
                return {}

        except Exception as e:
            print(f"âŒ ç”ŸæˆéŒ¯èª¤: {e}")
            return {}

    def ab_test(
        self,
        prompts: List[str],
        test_name: str,
        params: Dict[str, any] = None,
        iterations: int = 3,
    ) -> Dict:
        """A/B æ¸¬è©¦ä¸åŒæç¤ºè©çš„æ•ˆæœ"""

        results = {
            "test_name": test_name,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "prompts": [],
            "comparison": {},
        }

        print(f"ğŸ§ª é–‹å§‹ A/B æ¸¬è©¦: {test_name}")

        for i, prompt in enumerate(prompts):
            prompt_results = {
                "id": f"prompt_{i+1}",
                "prompt": prompt,
                "token_analysis": self.analyze_tokens(prompt),
                "generations": [],
            }

            print(f"  æ¸¬è©¦æç¤ºè© {i+1}/{len(prompts)}")

            # å¤šæ¬¡ç”Ÿæˆæ¸¬è©¦
            for iteration in range(iterations):
                generation = self.generate_text(prompt, params)
                if generation:
                    prompt_results["generations"].append(
                        {
                            "iteration": iteration + 1,
                            "text": generation.get("choices", [{}])[0].get("text", ""),
                            "usage": generation.get("usage", {}),
                            "finish_reason": generation.get("choices", [{}])[0].get(
                                "finish_reason", ""
                            ),
                        }
                    )

            results["prompts"].append(prompt_results)

        # ç”Ÿæˆæ¯”è¼ƒå ±å‘Š
        results["comparison"] = self._analyze_ab_results(results["prompts"])

        # å„²å­˜çµæœ
        self._save_ab_results(results)

        return results

    def _analyze_ab_results(self, prompt_results: List[Dict]) -> Dict:
        """åˆ†æ A/B æ¸¬è©¦çµæœ"""
        comparison = {
            "token_efficiency": {},
            "generation_quality": {},
            "consistency": {},
            "recommendation": "",
        }

        for result in prompt_results:
            prompt_id = result["id"]

            # Token æ•ˆç‡åˆ†æ
            token_info = result["token_analysis"]
            comparison["token_efficiency"][prompt_id] = {
                "token_count": token_info.get("token_count", 0),
                "efficiency_score": token_info.get("efficiency_score", 0),
            }

            # ç”Ÿæˆå“è³ªåˆ†æ
            generations = result["generations"]
            if generations:
                avg_length = sum(len(gen["text"]) for gen in generations) / len(
                    generations
                )
                completion_rate = sum(
                    1 for gen in generations if gen["finish_reason"] == "stop"
                ) / len(generations)

                comparison["generation_quality"][prompt_id] = {
                    "avg_output_length": avg_length,
                    "completion_rate": completion_rate,
                    "generation_count": len(generations),
                }

        # ç”Ÿæˆå»ºè­°
        best_prompt = max(
            comparison["token_efficiency"].keys(),
            key=lambda x: comparison["generation_quality"][x]["completion_rate"],
        )

        comparison["recommendation"] = f"å»ºè­°ä½¿ç”¨ {best_prompt}ï¼Œå…·æœ‰æœ€ä½³çš„å®Œæˆç‡"

        return comparison

    def _save_ab_results(self, results: Dict):
        """å„²å­˜ A/B æ¸¬è©¦çµæœ"""
        filename = f"ab_test_{results['test_name']}_{int(time.time())}.json"
        filepath = self.results_dir / filename

        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(results, f, ensure_ascii=False, indent=2)

        print(f"ğŸ“Š æ¸¬è©¦çµæœå·²å„²å­˜: {filepath}")

    def optimize_prompt(
        self, base_prompt: str, optimization_goals: List[str], test_iterations: int = 5
    ) -> Dict:
        """æ™ºèƒ½æç¤ºè©æœ€ä½³åŒ–"""

        print(f"ğŸ”§ é–‹å§‹æç¤ºè©æœ€ä½³åŒ–...")

        # åŸºç¤åˆ†æ
        base_analysis = self.analyze_tokens(base_prompt)

        # ç”Ÿæˆæœ€ä½³åŒ–å»ºè­°
        optimizations = []

        if "token_efficiency" in optimization_goals:
            optimizations.append(self._suggest_token_optimization(base_prompt))

        if "clarity" in optimization_goals:
            optimizations.append(self._suggest_clarity_optimization(base_prompt))

        if "specificity" in optimization_goals:
            optimizations.append(self._suggest_specificity_optimization(base_prompt))

        # æ¸¬è©¦æœ€ä½³åŒ–ç‰ˆæœ¬
        optimization_results = []

        for opt in optimizations:
            if opt["optimized_prompt"]:
                test_result = self.ab_test(
                    [base_prompt, opt["optimized_prompt"]],
                    f"optimization_{opt['type']}",
                    iterations=test_iterations,
                )
                optimization_results.append(
                    {
                        "type": opt["type"],
                        "suggestion": opt["suggestion"],
                        "test_result": test_result,
                    }
                )

        return {
            "base_prompt": base_prompt,
            "base_analysis": base_analysis,
            "optimization_goals": optimization_goals,
            "optimizations": optimization_results,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        }

    def _suggest_token_optimization(self, prompt: str) -> Dict:
        """å»ºè­° token æœ€ä½³åŒ–"""
        # ç°¡å–®çš„æœ€ä½³åŒ–é‚è¼¯ - ç§»é™¤å†—é¤˜è©å½™
        optimized = re.sub(r"\b(è«‹|éº»ç…©|èƒ½å¦|å¯ä»¥)\b", "", prompt)
        optimized = re.sub(r"\s+", " ", optimized).strip()

        return {
            "type": "token_efficiency",
            "suggestion": "ç§»é™¤å†—é¤˜è©å½™ä»¥æé«˜ token æ•ˆç‡",
            "optimized_prompt": optimized if optimized != prompt else None,
        }

    def _suggest_clarity_optimization(self, prompt: str) -> Dict:
        """å»ºè­°æ¸…æ™°åº¦æœ€ä½³åŒ–"""
        # æ·»åŠ çµæ§‹åŒ–è¦æ±‚
        if "ï¼š" not in prompt and ":" not in prompt:
            optimized = f"{prompt}\n\nè«‹ä»¥æ¸…æ¥šçš„çµæ§‹å›æ‡‰ï¼ŒåŒ…å«ï¼š\n1. ä¸»è¦å…§å®¹\n2. å…·é«”ç¯„ä¾‹\n3. ç¸½çµ"
        else:
            optimized = None

        return {
            "type": "clarity",
            "suggestion": "æ·»åŠ çµæ§‹åŒ–è¦æ±‚ä»¥æé«˜å›æ‡‰æ¸…æ™°åº¦",
            "optimized_prompt": optimized,
        }

    def _suggest_specificity_optimization(self, prompt: str) -> Dict:
        """å»ºè­°å…·é«”æ€§æœ€ä½³åŒ–"""
        # æ·»åŠ å…·é«”çš„è¼¸å‡ºè¦æ±‚
        if "å­—æ•¸" not in prompt and "é•·åº¦" not in prompt:
            optimized = f"{prompt}\n\nè¦æ±‚ï¼šå›æ‡‰é•·åº¦ç´„ 200-400 å­—ï¼ŒåŒ…å«å…·é«”ç¯„ä¾‹ã€‚"
        else:
            optimized = None

        return {
            "type": "specificity",
            "suggestion": "æ·»åŠ å…·é«”çš„è¼¸å‡ºé•·åº¦å’Œæ ¼å¼è¦æ±‚",
            "optimized_prompt": optimized,
        }

    def list_templates(self, category: str = None) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰ç¯„æœ¬"""
        if category:
            return [
                name
                for name, template in self.templates.items()
                if template.category == category
            ]
        else:
            return list(self.templates.keys())

    def search_templates(self, query: str) -> List[str]:
        """æœå°‹ç¯„æœ¬"""
        results = []
        query = query.lower()

        for name, template in self.templates.items():
            if (
                query in name.lower()
                or query in template.description.lower()
                or any(query in tag.lower() for tag in template.tags)
            ):
                results.append(name)

        return results


def main():
    """ä¸»è¦åŸ·è¡Œå‡½æ•¸"""
    print("ğŸš€ TGW Prompt Engineering Tool")
    print("=" * 50)

    # åˆå§‹åŒ–å·¥å…·
    engineer = TGWPromptEngineer()

    # å»ºç«‹ç¯„ä¾‹ç¯„æœ¬
    print("ğŸ“ å»ºç«‹ç¯„ä¾‹ç¯„æœ¬...")

    # æŠ€è¡“æ–‡æª”ç¯„æœ¬
    engineer.create_template(
        name="api_documentation",
        category="technical",
        template="""è«‹ç‚ºä»¥ä¸‹ API ç«¯é»ç”Ÿæˆå®Œæ•´æ–‡æª”ï¼š

ç«¯é»ï¼š{endpoint_url}
æ–¹æ³•ï¼š{http_method}
åŠŸèƒ½ï¼š{description}

è«‹åŒ…å«ï¼š
1. ç«¯é»æè¿°
2. è«‹æ±‚åƒæ•¸ï¼ˆå¿…å¡«/é¸å¡«ï¼‰
3. è«‹æ±‚ç¯„ä¾‹
4. å›æ‡‰æ ¼å¼
5. éŒ¯èª¤ä»£ç¢¼èªªæ˜

æ ¼å¼ï¼šMarkdownï¼ŒåŒ…å«ç¨‹å¼ç¢¼å€å¡Š""",
        description="ç”Ÿæˆ API æŠ€è¡“æ–‡æª”çš„æ¨™æº–ç¯„æœ¬",
        tags=["technical", "api", "documentation"],
        optimal_params={"temperature": 0.3, "top_p": 0.8, "repetition_penalty": 1.05},
    )

    # å‰µæ„å¯«ä½œç¯„æœ¬
    engineer.create_template(
        name="creative_writing",
        category="creative",
        template="""å‰µä½œä¸€å€‹{genre}æ•…äº‹ï¼š

èƒŒæ™¯è¨­å®šï¼š{setting}
ä¸»è§’ï¼š{protagonist}
è¡çªï¼š{conflict}
å­—æ•¸ï¼š{word_count}å­—

è¦æ±‚ï¼š
1. å¼•äººå…¥å‹çš„é–‹é ­
2. ç”Ÿå‹•çš„è§’è‰²æå¯«
3. ç·Šæ¹Šçš„æƒ…ç¯€ç™¼å±•
4. ç¬¦åˆ{genre}é¡å‹ç‰¹è‰²""",
        description="å‰µæ„å¯«ä½œå’Œæ•…äº‹å‰µä½œç¯„æœ¬",
        tags=["creative", "writing", "story"],
        optimal_params={"temperature": 0.8, "top_p": 0.95, "repetition_penalty": 1.1},
    )

    print("âœ… ç¯„ä¾‹ç¯„æœ¬å»ºç«‹å®Œæˆ")
    print(f"ğŸ“‚ ç¯„æœ¬å„²å­˜ä½ç½®: {engineer.templates_dir}")
    print(f"ğŸ“Š çµæœå„²å­˜ä½ç½®: {engineer.results_dir}")


if __name__ == "__main__":
    main()
